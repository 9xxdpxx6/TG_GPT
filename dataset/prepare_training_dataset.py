import json
import os
import re
from pathlib import Path
from collections import defaultdict

def clean_text(text):
    """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç —ç–º–æ–¥–∑–∏, —Å—Å—ã–ª–æ–∫ –∏ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    if isinstance(text, list):
        text = ''.join([str(t['text']) if isinstance(t, dict) else str(t) for t in text])
    
    # –£–¥–∞–ª—è–µ–º —ç–º–æ–¥–∑–∏ –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    text = re.sub(r'[^\w\s.,!?\-:;()]', ' ', str(text))
    # –£–¥–∞–ª—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def process_chat_file(file_path, your_name="Andrey"):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω JSON-—á–∞—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–∏–∞–ª–æ–≥–æ–≤"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        conversations = []
        current_context = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –ª–∏—á–Ω—ã–π —á–∞—Ç
        if data.get('type') != 'personal_chat':
            return conversations
        
        for msg in data.get('messages', []):
            if msg.get('type') != 'message' or 'text' not in msg:
                continue
                
            sender = msg.get('from', '')
            text = clean_text(msg['text'])
            
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ —Å–ª—É–∂–µ–±–Ω—ã–µ
            if not text or len(text) < 2 or text.startswith('http'):
                continue
                
            if sender == your_name:
                # –ï—Å–ª–∏ —ç—Ç–æ –≤–∞—à–µ —Å–æ–æ–±—â–µ–Ω–∏–µ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –æ—Ç–≤–µ—Ç
                if current_context:
                    conversations.append({
                        "context": current_context.copy(),
                        "response": text,
                        "source_file": os.path.basename(file_path),
                        "chat_name": data.get('name', 'Unknown')
                    })
                    current_context = []  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –≤–∞—à–µ–≥–æ –æ—Ç–≤–µ—Ç–∞
            else:
                # –°–æ–æ–±—â–µ–Ω–∏–µ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
                current_context.append(text)
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 —Å–æ–æ–±—â–µ–Ω–∏—è)
                if len(current_context) > 3:
                    current_context.pop(0)
        
        return conversations
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_path}: {e}")
        return []

def create_training_dataset():
    """–°–æ–∑–¥–∞–µ—Ç –µ–¥–∏–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ –≤—Å–µ—Ö —á–∞—Ç–æ–≤"""
    
    # –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å —á–∞—Ç–∞–º–∏
    chats_folder = Path("2025_08_12")
    
    if not chats_folder.exists():
        print(f"–ü–∞–ø–∫–∞ {chats_folder} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return
    
    all_conversations = []
    total_files = 0
    processed_files = 0
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ JSON —Ñ–∞–π–ª—ã
    for json_file in chats_folder.glob("*.json"):
        total_files += 1
        print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {json_file.name}")
        
        conversations = process_chat_file(json_file)
        if conversations:
            all_conversations.extend(conversations)
            processed_files += 1
            print(f"  -> –ù–∞–π–¥–µ–Ω–æ {len(conversations)} –¥–∏–∞–ª–æ–≥–æ–≤")
        else:
            print(f"  -> –î–∏–∞–ª–æ–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    print(f"\n=== –†–ï–ó–£–õ–¨–¢–ê–¢ ===")
    print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {processed_files}/{total_files}")
    print(f"–í—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤: {len(all_conversations)}")
    
    if all_conversations:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –¥–∞—Ç–∞—Å–µ—Ç
        output_file = "training_dataset.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_conversations, f, ensure_ascii=False, indent=2)
        print(f"–î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_file}")
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = {
            "total_conversations": len(all_conversations),
            "processed_files": processed_files,
            "total_files": total_files,
            "chat_sources": {},
            "context_lengths": [],
            "response_lengths": []
        }
        
        for conv in all_conversations:
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
            source = conv['source_file']
            stats['chat_sources'][source] = stats['chat_sources'].get(source, 0) + 1
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–ª–∏–Ω–µ
            stats['context_lengths'].append(len(conv['context']))
            stats['response_lengths'].append(len(conv['response']))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats_file = "dataset_statistics.json"
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {stats_file}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
        print(f"\n=== –ü–†–ò–ú–ï–†–´ –î–ò–ê–õ–û–ì–û–í ===")
        for i, conv in enumerate(all_conversations[:3]):
            print(f"\n–ü—Ä–∏–º–µ—Ä {i+1} (–∏–∑ {conv['source_file']}):")
            print(f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {conv['context']}")
            print(f"–í–∞—à –æ—Ç–≤–µ—Ç: {conv['response']}")
            print("-" * 50)
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print(f"\n=== –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò ===")
        if len(all_conversations) < 500:
            print("‚ö†Ô∏è  –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è! –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 500 –¥–∏–∞–ª–æ–≥–æ–≤.")
            print("   –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–æ–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ —á–∞—Ç–æ–≤ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å data augmentation.")
        elif len(all_conversations) < 2000:
            print("‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (500-2000 –¥–∏–∞–ª–æ–≥–æ–≤)")
            print("   –ú–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å, –Ω–æ –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ä–µ–¥–Ω–∏–º.")
        else:
            print("üéâ –û—Ç–ª–∏—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö! (>2000 –¥–∏–∞–ª–æ–≥–æ–≤)")
            print("   –ú–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ —Ö–æ—Ä–æ—à–æ –æ–±—É—á–∏—Ç—å—Å—è –≤–∞—à–µ–º—É —Å—Ç–∏–ª—é.")
        
        print(f"\n–¢–µ–ø–µ—Ä—å –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ–∞–π–ª '{output_file}' –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏!")
        
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–∏–∞–ª–æ–≥–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
        print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:")
        print("1. –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—ã JSON —Ñ–∞–π–ª–æ–≤")
        print("2. –ù–∞–ª–∏—á–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è 'Andrey'")
        print("3. –§–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞ –∏–∑ Telegram")

if __name__ == "__main__":
    print("üöÄ –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏...")
    print("=" * 50)
    create_training_dataset() 